<ul>
<li>링크: <a href="https://n.news.naver.com/mnews/article/009/0005496536">네이버 오픈소스 AI모델 '인기몰이'</a></li>
</ul>
<hr />
<h1 id="주요-성과">주요 성과</h1>
<ul>
<li>모델 공개일: 2025년 4월 24일 (허깅페이스에 업로드)\</li>
<li>다운로드 수:<ul>
<li>‘하이퍼클로바X 시드 3B’: 12.7만건</li>
<li>1.5B, 0.5B 포함 총 15만건 돌파</li>
</ul>
</li>
<li>의미: MS 등 빅테크 모델보다 높은 다운로드 수 → 국내 최초급 의미 있는 오픈소스 LLM 사례</li>
</ul>
<hr />
<h1 id="모델-정보">모델 정보</h1>
<table>
<thead>
<tr>
<th>모델명</th>
<th>크기</th>
<th>특성</th>
</tr>
</thead>
<tbody><tr>
<td><strong>3B</strong></td>
<td>30억 파라미터</td>
<td><strong>텍스트 + 이미지 + 영상</strong> 이해 가능 (멀티모달)</td>
</tr>
<tr>
<td><strong>1.5B</strong></td>
<td>중간 크기</td>
<td>텍스트 특화, 경량</td>
</tr>
<tr>
<td><strong>0.5B</strong></td>
<td>소형 모델</td>
<td>빠르고 비용효율적</td>
</tr>
<tr>
<td>---</td>
<td></td>
<td></td>
</tr>
<tr>
<td># 성능 비교 (한국어 벤치마크 기준)</td>
<td></td>
<td></td>
</tr>
<tr>
<td>- 하이퍼클로바X 시드 3B &gt; 알리바바 큐원2.5 3B, 구글 젬마3 4B</td>
<td></td>
<td></td>
</tr>
<tr>
<td>- 의미: 한국어 성능 기준으로 글로벌 모델보다 우수</td>
<td></td>
<td></td>
</tr>
<tr>
<td>---</td>
<td></td>
<td></td>
</tr>
<tr>
<td># 업계 동향</td>
<td></td>
<td></td>
</tr>
<tr>
<td>- 카카오: 2025년 2월, 카나나 나노 2.1B 공개</td>
<td></td>
<td></td>
</tr>
<tr>
<td>- LG AI연구원: ‘엑사원(Exaone)’ 시리즈로 LLM 개발 중</td>
<td></td>
<td></td>
</tr>
</tbody></table>