<h1 id="7-데이터-윤리-및-보안">7. 데이터 윤리 및 보안</h1>
<h2 id="📌-1-개인정보-보호법-및-데이터-3법">📌 1. 개인정보 보호법 및 데이터 3법</h2>
<h3 id="🔹-개인정보-보호법-대한민국">🔹 개인정보 보호법 (대한민국)</h3>
<ul>
<li>개인의 정보 자기결정권 보호를 위한 법률</li>
<li>주민등록번호, 연락처, 계좌번호 등 <strong>개인 식별 가능한 정보(PII)</strong>의 수집·활용을 엄격히 제한</li>
<li>과도한 수집 금지, 수집 목적 명확화, 제3자 제공 시 동의 필수 등</li>
</ul>
<h3 id="🔹-데이터-3법-2020년-개정">🔹 데이터 3법 (2020년 개정)</h3>
<ol>
<li><strong>개인정보 보호법</strong>: 개인정보 처리 및 보호 규정 강화</li>
<li><strong>정보통신망법</strong>: 온라인 상의 개인정보 보호 중심</li>
<li><strong>신용정보법</strong>: 금융 정보 보호 + 마이데이터 사업 기반 마련</li>
</ol>
<blockquote>
<p>이 법 개정을 통해 <strong>가명정보 활용 가능</strong> → 빅데이터 산업 활성화</p>
</blockquote>
<hr />
<h2 id="📌-2-데이터-보안-기술">📌 2. 데이터 보안 기술</h2>
<h3 id="🔹-데이터-마스킹-masking">🔹 데이터 마스킹 (Masking)</h3>
<ul>
<li>민감 정보 일부를 마스킹 처리하여 식별 불가능하게 변환<pre><code class="language-python">email = &quot;user@example.com&quot;
masked = email[0] + &quot;***&quot; + email[email.index(&quot;@&quot;):]  # u***@example.com</code></pre>
</li>
</ul>
<h3 id="🔹-데이터-익명화-anonymization">🔹 데이터 익명화 (Anonymization)</h3>
<ul>
<li>개인을 특정할 수 없도록 완전한 식별 정보 제거</li>
<li>반대로 <strong>복원 가능성이 없는 수준</strong>으로 처리해야 법적 요건 충족</li>
</ul>
<h3 id="🔹-데이터-암호화-encryption">🔹 데이터 암호화 (Encryption)</h3>
<ul>
<li>데이터를 특정 키로 암호화하여 보호</li>
<li>AES, RSA 등 대칭/비대칭 암호화 알고리즘 사용<pre><code class="language-python">from cryptography.fernet import Fernet
</code></pre>
</li>
</ul>
<p>key = Fernet.generate_key()
cipher = Fernet(key)
token = cipher.encrypt(b&quot;my sensitive data&quot;)
print(cipher.decrypt(token))</p>
<pre><code>
---

## 📌 3. 알고리즘 편향성과 투명성

### 🔹 알고리즘 편향(Bias)
- 학습 데이터가 불균형하거나, 편견이 반영된 경우 모델 결과에 편향 발생
- 예: 채용 AI가 특정 성별을 더 많이 추천하는 경우

### 🔹 알고리즘 투명성
- 결과가 어떻게 도출되었는지를 설명할 수 있어야 함
- **XAI(eXplainable AI)** 기술 필요성 대두

&gt; 투명한 알고리즘은 책임성, 공정성 확보에 기여

---

## 📌 4. 데이터 활용의 윤리적 이슈

### 🔹 사전 동의와 목적 제한 원칙
- 데이터 수집 및 사용은 **명확한 목적 + 사용자의 동의** 필요

### 🔹 데이터 소외 계층 문제
- 데이터 분석 결과가 특정 집단에 불리하게 작용하지 않도록 고려해야 함

### 🔹 Deepfake, 감시 사회 논란
- AI 기술로 생성된 가짜 정보, 감시 강화 등에 대한 **사회적 합의 필요**
</code></pre>