<h1 id="1-olmocr-강화학습-데이터-구성">1. olmOCR 강화학습 데이터 구성</h1>
<h2 id="a-요약">a. 요약</h2>
<ul>
<li><code>GRPO</code>에 사용되는 데이터는 <code>olmOCR-bench</code> 포맷을 그대로 사용함. 학습 입력은 <code>bench_data/pdfs/**</code>의 PDF 단일 페이지 이미지와, 각 페이지에 대한 테스트 정의<code>(JSONL)</code> 파일로 구성되어 있음</li>
<li><code>SFT</code>에서 사용하는 학습, 검증 데이터는 사용하지 않음. 각각 다른 데이터셋을 활용함<h2 id="b-데이터셋-구조">b. 데이터셋 구조</h2>
<pre><code class="language-text">bench_data_folder/
├── pdfs/                    # 원본 PDF 파일들
├── *.jsonl                  # 테스트 케이스 정의
└── claude_original/         # Claude 생성 참조 마크다운
  └── {pdf_dir}/
      └── {pdf_name}_page{page}_pg1_repeat1.md</code></pre>
<h2 id="c-jsonl-레코드-형식">c. JSONL 레코드 형식</h2>
<h3 id="jsonl-샘플">JSONL 샘플</h3>
<pre><code class="language-JSON">{&quot;pdf&quot;: &quot;multi_column_miss.pdf&quot;, &quot;page&quot;: 1, &quot;id&quot;: &quot;multi_column_miss_00&quot;, &quot;type&quot;: &quot;present&quot;, &quot;text&quot;: &quot;Corporate social responsibility and the tobacco industry: hope or hype?&quot;}
{&quot;pdf&quot;: &quot;multi_column_miss.pdf&quot;, &quot;page&quot;: 1, &quot;id&quot;: &quot;multi_column_miss_01&quot;, &quot;type&quot;: &quot;present&quot;, &quot;text&quot;: &quot;this leaves BAT to argue why it should not be held to be largely accountable for the annual deaths of some 754 600 smokers, and Philip Morris some 803 600 smokers.&quot;}
{&quot;pdf&quot;: &quot;multi_column_miss.pdf&quot;, &quot;page&quot;: 1, &quot;id&quot;: &quot;multi_column_miss_02&quot;, &quot;type&quot;: &quot;present&quot;, &quot;text&quot;: &quot;The term \&quot;corporate social responsibility\&quot; is in vogue at the moment but as a concept it is vague and means different things to different people.&quot;, &quot;max_diffs&quot;: 2}
{&quot;pdf&quot;: &quot;multi_column_miss.pdf&quot;, &quot;page&quot;: 1, &quot;id&quot;: &quot;multi_column_miss_03&quot;, &quot;type&quot;: &quot;present&quot;, &quot;text&quot;: &quot;Over the past three decades increasing pressure from non-governmental&quot;}
{&quot;pdf&quot;: &quot;multi_column_miss.pdf&quot;, &quot;page&quot;: 1, &quot;id&quot;: &quot;multi_column_miss_04&quot;, &quot;type&quot;: &quot;absent&quot;, &quot;text&quot;: &quot;Downloaded from http://tobaccocontrol.bmj.com/&quot;}
</code></pre>
</li>
</ul>
<p>{&quot;pdf&quot;: &quot;multi_column_miss.pdf&quot;, &quot;page&quot;: 1, &quot;id&quot;: &quot;multi_column_miss_10&quot;, &quot;type&quot;: &quot;order&quot;, &quot;before&quot;: &quot;Corporate social responsibility and the tobacco industry: hope or hype?&quot;, &quot;after&quot;: &quot;The unprecedented expansion of power and influence of TNCs over the past three decades has accelerated global trade and development, but also environmental damage and abuses of&quot;, &quot;max_diffs&quot;: 2}
{&quot;pdf&quot;: &quot;multi_column_miss.pdf&quot;, &quot;page&quot;: 1, &quot;id&quot;: &quot;multi_column_miss_11&quot;, &quot;type&quot;: &quot;order&quot;, &quot;before&quot;: &quot;It now looks like that with vigilance&quot;, &quot;after&quot;: &quot;this leaves BAT to argue why it should not be held to be largely accountable for the annual deaths&quot;,  &quot;max_diffs&quot;: 2}
{&quot;pdf&quot;: &quot;multi_column_miss.pdf&quot;, &quot;page&quot;: 1, &quot;id&quot;: &quot;multi_column_miss_12&quot;, &quot;type&quot;: &quot;order&quot;, &quot;before&quot;: &quot;Corporate social responsibility (CSR) emerged from a realisation among transnational corporations&quot;, &quot;after&quot;: &quot; perspective on its own behaviour; and reflects on whether marketing tobacco is antithetical to social responsibility.&quot;, &quot;max_diffs&quot;: 2}</p>
<p>{&quot;pdf&quot;: &quot;discoverworld_crazy_table4.pdf&quot;, &quot;page&quot;: 1, &quot;id&quot;: &quot;discoverworld_crazy_table4_00&quot;, &quot;type&quot;: &quot;present&quot;, &quot;text&quot;: &quot;Table 4: Baseline model performance on each of the three scoring metrics&quot;}
{&quot;pdf&quot;: &quot;discoverworld_crazy_table4.pdf&quot;, &quot;page&quot;: 1, &quot;id&quot;: &quot;discoverworld_crazy_table4_01&quot;, &quot;type&quot;: &quot;present&quot;, &quot;text&quot;: &quot;Table 5: Baseline model performance on each of the three scoring metrics&quot;}
{&quot;pdf&quot;: &quot;discoverworld_crazy_table4.pdf&quot;, &quot;page&quot;: 1, &quot;id&quot;: &quot;discoverworld_crazy_table4_02&quot;, &quot;type&quot;: &quot;present&quot;, &quot;text&quot;: &quot;We use the GPT-4O model for all our agents due to its higher performance and lower cost compared to other models. For space we provide&quot;}</p>
<pre><code>
### - 공통 필드
| 필드       | 설명                                                                           |
| -------- | ---------------------------------------------------------------------------- |
| **pdf**  | 테스트 대상이 되는 PDF 파일 이름. 예: `&quot;arxiv_2301.0123.pdf&quot;`                             |
| **page** | 해당 테스트가 적용되는 PDF 페이지 번호 (0-index 또는 1-index). 예: `3`                         |
| **id**   | 고유 식별자 (UUID 또는 문자열). 테스트 결과를 추적하기 위해 사용.                                    |
| **type** | 테스트의 종류를 명시. `present`, `absent`, `order`, `table`, `math`, `baseline` 중 하나. |
### - `absent`, `present`
- 특정 텍스트가 OCR 결과에 존재해야 하는지 또는 존재하지 않아야 하는지 검사

| 필드                   | 설명                           |
| -------------------- | ------------------ |
| **text**             | 찾고자 하는 문자열. 예: `&quot;Neural Networks&quot;`                                  |
| **max_diffs**        | 허용되는 최대 오탈자(문자 차이) 수. 문자열 유사도(`Levenshtein distance`) 계산 시 사용.      |
| **case_sensitive**   | 대소문자 구분 여부 (`true`면 &quot;Math&quot;와 &quot;math&quot;는 다름).                            |
| **first_n / last_n** | PDF 텍스트의 앞부분 혹은 뒷부분만 검사할 때 범위를 지정 (예: `first_n=500` → 처음 500자만 검사). |
### - `order`
- 특정 두 구절이 순서대로 등장하는지 등을 확인

| 필드            | 설명              |
| -------- | ------- |
| **before**    | 앞에 나와야 하는 문자열         |
| **after**     | 뒤에 나와야 하는 문자열         |
| **max_diffs** | 오탈자 허용치. 두 문자열 모두에 적용 |
### - `table`
- 표 인식 정확도를 검사, 각 셀의 내용이 올바른지, 방향 참조가 정확한지 등을 확인함

| 필드                             | 설명                                                    |
| ------------------------------ | ----------------------------------------------------- |
| **cell**                       | 기준 셀 위치 또는 내용.                                        |
| **up/down/left/right**         | 인접 셀 방향 참조 (예: `up=&quot;Header&quot;` → 바로 위 셀이 &quot;Header&quot;여야 함). |
| **top_heading / left_heading** | 표의 제목행/열에서 기대되는 텍스트.                                  |
### - `math`
- 수식 인식 정확도를 확인함

| 필드                          | 설명                                                           |
| --------------------------- | ------------------------------------------------------------ |
| **math**                    | 정답 LaTeX 표현식. 예: `&quot;E = mc^2&quot;`                                |
| **ignore_dollar_delimited** | `$...$` 구문을 무시할지 여부 (`true`면 `$E=mc^2$`과 `E=mc^2`을 동일하게 처리). |

### - `baseline`
- 페이지 전체 품질 점검용 테스트, 모델이 불필요한 기호를 출력하지 않았는지, 텍스트 길이가 너무 짧거나 긴 지 등을 체크

| 필드                                  | 설명                                               |
| ----------------------------------- | ------------------------------------------------ |
| **max_length**                      | OCR 결과의 최대 허용 길이. 너무 길면 과출력(over-generation) 판정. |
| **max_length_skips_image_alt_tags** | 이미지 대체 텍스트(`&lt;img alt=&quot;...&quot;&gt;`)는 길이 계산에서 제외할지 여부.  |
| **max_repeats**                     | 동일 문자 반복 허용 횟수 (예: `&quot;=====&quot;` 5회 초과 시 실패).        |
| **check_disallowed_characters**     | 허용되지 않은 특수문자 검사 여부 (`true`면 Unicode 범위 기반 필터링).  |

### - JSONL 파일의 역할
- JSONL = 페이지별 테스트 카탈로그
- 데이터셋 단계: JSONL → (pdf,page)별 test_ids 집계
- 보상 단계: 해당 JSONL에서 test_ids만 파싱 → test.run(model_output) → 통과율이 보상

### - `test_ids`
- `JSONL` 파일에 정의된 개별 테스트 항목을 가리티는 고유한 식별자
- 유닛 테스트를 진행할 때 사용됨
- `JSONL` 파일의 각 줄이 하나의 테스트 케이스이며, 그 테스트 케이스의 이름이 `test_ids`
- 보상 계산 단계에서 어떤 테스트를 실행할지 정확히 지정하는 역할로 사용됨

### d. `claude_original`
- Claude-Sonnet 모델로 생성한 고품질 참조 마크다운 파일, PDF 페이지를 OCR한 결과로, 모델 출력과 비교하는 기준으로 사용됨
- 보상 계산: 모델의 출력과 비교하여 계산
- 없어도 학습 가능(해당 보상 함수만 비활성화됨)
- 편집 거리 기반 유사도, Front matter 필드 비교, 테이블/수식 개수 비교
---
## 2. 강화학습 프롬프트 조사
```python
def build_no_anchoring_v4_yaml_prompt() -&gt; str:
    return (
        &quot;Attached is one page of a document that you must process. &quot;
        &quot;Just return the plain text representation of this document as if you were reading it naturally. Convert equations to LateX and tables to HTML.\n&quot;
        &quot;If there are any figures or charts, label them with the following markdown syntax ![Alt text describing the contents of the figure](page_startx_starty_width_height.png)\n&quot;
        &quot;Return your output as markdown, with a front matter section on top specifying values for the primary_language, is_rotation_valid, rotation_correction, is_table, and is_diagram parameters.&quot;
    )</code></pre><ul>
<li>추론 진행할 때 사용했던 프롬프트와 같음(앵커링 정보 x)</li>
</ul>
<hr />
<h2 id="3-진행했던-강화학습-코드-분석">3. 진행했던 강화학습 코드 분석</h2>
<h3 id="a-초기화-및-설정">a. 초기화 및 설정</h3>
<pre><code class="language-python">&quot;&quot;&quot;
grpo_train.py
766-862
&quot;&quot;&quot;
def main():
    # 분산학습 프로세스(rank) 정보 확인 및 출력
    rank = get_rank()
    if &quot;LOCAL_RANK&quot; in os.environ:
        logger.info(f&quot;LOCAL_RANK environment variable: {os.environ['LOCAL_RANK']}&quot;)
    if &quot;RANK&quot; in os.environ:
        logger.info(f&quot;RANK environment variable: {os.environ['RANK']}&quot;)
    logger.info(f&quot;Current process rank: {rank}, is_main_process: {is_main_process()}&quot;)

    parser = argparse.ArgumentParser(description=&quot;GRPO training for OlmOCR&quot;)
    parser.add_argument(
        &quot;--train_bench_data_folder&quot;, type=str, required=True, help=&quot;Path to training bench data folder containing JSONL files and pdfs subfolder&quot;
    )
    ...
    args = parser.parse_args()

    # 출력 디렉토리 생성
    os.makedirs(args.output_dir, exist_ok=True)

    # 메인 프로세스만(rank 0) W&amp;B 초기화
    if is_main_process():
        wandb.init(project=args.wandb_project, name=args.wandb_run_name, config=vars(args))
        logger.info(f&quot;Initialized wandb project: {args.wandb_project} (rank {get_rank()})&quot;)
        report_to = [&quot;wandb&quot;]
    else:
        logger.info(f&quot;Skipping wandb initialization on rank {get_rank()}&quot;)
        report_to = []  </code></pre>
<ul>
<li>GRPO 기반 분산 학습 파이프라인의 초기 단계</li>
</ul>
<h3 id="b-데이터셋-로딩">b. 데이터셋 로딩</h3>
<pre><code class="language-python">&quot;&quot;&quot;
grpo_train.py
906-930
&quot;&quot;&quot;
    # 학습 데이터셋 생성
    logger.info(f&quot;Creating training dataset from: {args.train_bench_data_folder}&quot;)
    train_dataset = OlmOCRBenchDataset(
        bench_data_folder=args.train_bench_data_folder,
        processor=processor,
        max_samples=args.max_train_samples,
        target_longest_image_dim=1288,
    )

    if len(train_dataset) == 0:
        logger.error(&quot;No samples found in training dataset!&quot;)
        return

    # 병가 데이터셋 생성
    logger.info(f&quot;Creating evaluation dataset from: {args.eval_bench_data_folder}&quot;)
    eval_dataset = OlmOCRBenchDataset(
        bench_data_folder=args.eval_bench_data_folder,
        processor=processor,
        max_samples=args.max_eval_samples,
        target_longest_image_dim=1288,
    )

    # 평가 데이터셋 없을 때 학습 데이터셋을 평가 데이터셋으로 사용함
    if len(eval_dataset) == 0:
        logger.warning(&quot;No samples found in evaluation dataset, using training dataset for eval&quot;)
        eval_dataset = train_dataset</code></pre>
<h3 id="c-모델-로딩">c. 모델 로딩</h3>
<pre><code class="language-python">&quot;&quot;&quot;
grpo_train.py
886-904
&quot;&quot;&quot;
    # 프로세서 로드
    logger.info(f&quot;Loading processor: {args.model_name}&quot;)
    processor = AutoProcessor.from_pretrained(
        args.model_name,
        trust_remote_code=True,
    )

    # 모델 로드
    logger.info(f&quot;Loading model: {args.model_name}&quot;)
    if &quot;Qwen2-VL&quot; in args.model_name:
        model_class = Qwen2VLForConditionalGeneration
    else:
        model_class = Qwen2_5_VLForConditionalGeneration

    model = model_class.from_pretrained(
        args.model_name,
        torch_dtype=torch.bfloat16,
        trust_remote_code=True,
    )</code></pre>
<ul>
<li><p>기본 모델: <code>Qwen/Qwen2.5-VL-7B-Instruct</code> </p>
</li>
<li><p><code>bfloat16</code> 연산 방식 사용</p>
</li>
<li><p>프로세서와 모델 로딩</p>
<h3 id="d-보상함수-설정">d. 보상함수 설정</h3>
<pre><code class="language-python">&quot;&quot;&quot;
grpo_train.py
932-994
&quot;&quot;&quot;
  # 보상 함수와 가중치 설정
  reward_funcs = []
  reward_weights = []
  reward_names = []

  # 단위 테스트 통과율
  if args.reward_bench is not None:
      reward_funcs.append(olmocr_bench_reward)
      reward_weights.append(args.reward_bench)
      reward_names.append(&quot;bench&quot;)
      logger.info(f&quot;Added bench-based reward function with weight {args.reward_bench}&quot;)

  # medoid 기준 유사도
  if args.reward_medoid is not None:
      reward_funcs.append(medoid_reward)
      reward_weights.append(args.reward_medoid)
      reward_names.append(&quot;medoid&quot;)
      logger.info(f&quot;Added medoid-based reward function with weight {args.reward_medoid}&quot;)

  # claude_original과의 편집 거리
  if args.reward_bench_edit_distance is not None:
      reward_funcs.append(bench_edit_distance_reward)
      reward_weights.append(args.reward_bench_edit_distance)
      reward_names.append(&quot;bench_edit_distance&quot;)
      logger.info(f&quot;Added bench edit distance reward function with weight {args.reward_bench_edit_distance}&quot;)

  # front matter 파싱 및 필드 매칭
  if args.reward_front_matter is not None:
      reward_funcs.append(reward_front_matter)
      reward_weights.append(args.reward_front_matter)
      reward_names.append(&quot;front_matter&quot;)
      logger.info(f&quot;Added front matter validation reward function with weight {args.reward_front_matter}&quot;)

  # 테이블/수식 개수 매칭
  if args.reward_element_count is not None:
      reward_funcs.append(reward_element_count)
      reward_weights.append(args.reward_element_count)
      reward_names.append(&quot;element_count&quot;)
      logger.info(f&quot;Added element count matching reward function with weight {args.reward_element_count}&quot;)

  # EOS 토큰 체크
  if args.reward_eos is not None:
      # Get EOS token ID from processor's tokenizer
      eos_token_id = processor.tokenizer.eos_token_id
      logger.info(f&quot;EOS token ID from tokenizer: {eos_token_id}&quot;)

      # Create a wrapper function with proper __name__ attribute
      def reward_eos_wrapper(prompts, completions, completion_ids, **kwargs):
          return reward_eos(eos_token_id, prompts, completions, completion_ids, **kwargs)

      reward_eos_wrapper.__name__ = &quot;reward_eos&quot;
      reward_funcs.append(reward_eos_wrapper)
      reward_weights.append(args.reward_eos)
      reward_names.append(&quot;eos&quot;)
      logger.info(f&quot;Added EOS token check reward function with weight {args.reward_eos}&quot;)

  if not reward_funcs:
      logger.error(
          &quot;No reward function specified. Use at least one of: --reward_bench, --reward_medoid, --reward_bench_edit_distance, --reward_front_matter, --reward_element_count, --reward_eos&quot;
      )
      return

  # Log summary of reward configuration
  logger.info(f&quot;\n&quot; + &quot;=&quot; * 50)
  logger.info(f&quot;Reward Configuration:&quot;)
  logger.info(f&quot;Using {len(reward_funcs)} reward function(s):&quot;)
  for name, weight in zip(reward_names, reward_weights):
      logger.info(f&quot;  - {name}: weight={weight}&quot;)
  logger.info(&quot;=&quot; * 50 + &quot;\n&quot;)</code></pre>
</li>
<li><p>보상함수 설명</p>
<h3 id="e-grpo-설정">e. GRPO 설정</h3>
<pre><code class="language-python">&quot;&quot;&quot;
grpo_train.py
996-1032
&quot;&quot;&quot;
  # Set up GRPO configuration
  grpo_config = GRPOConfig(
      output_dir=args.output_dir,
      num_train_epochs=args.num_train_epochs,
      per_device_train_batch_size=args.per_device_train_batch_size,
      per_device_eval_batch_size=args.per_device_eval_batch_size,
      gradient_accumulation_steps=args.gradient_accumulation_steps,
      learning_rate=args.learning_rate,
      logging_steps=10,
      save_steps=100,
      save_total_limit=3,
      eval_steps=50,
      warmup_steps=args.warmup_steps,
      max_prompt_length=3000,
      max_completion_length=3000,
      temperature=0.7,
      report_to=report_to,
      remove_unused_columns=False,
      bf16=True,
      shuffle_dataset=True,
      seed=args.seed,
      dataloader_num_workers=8,
      dataloader_drop_last=True,
      # GRPO-specific parameters
      loss_type=args.loss_type,
      scale_rewards=args.scale_rewards,
      beta=args.beta,
      importance_sampling_level=args.importance_sampling_level,
      reward_weights=reward_weights,
      num_iterations=args.num_iterations,
      num_generations=args.num_generations,
      # Vllm setup to speed up generation
      use_vllm=(args.vllm_mode != &quot;none&quot;),
      vllm_mode=args.vllm_mode if args.vllm_mode != &quot;none&quot; else &quot;colocate&quot;,
      vllm_gpu_memory_utilization=0.15,
      log_completions=True,
  )</code></pre>
</li>
<li><p>loss_type: <code>[&quot;bnpo&quot;, &quot;grpo&quot;, &quot;exo&quot;]</code>, 기본값은 <code>bnpo</code></p>
</li>
</ul>
<table>
<thead>
<tr>
<th>알고리즘</th>
<th>한 문장 설명</th>
</tr>
</thead>
<tbody><tr>
<td><strong>GRPO</strong></td>
<td>PPO의 critic을 없애고 advantage만으로 학습하는 간소화된 정책최적화</td>
</tr>
<tr>
<td><strong>BNPO</strong></td>
<td>GRPO의 보상 분산을 줄이기 위해 baseline 정규화를 추가한 버전</td>
</tr>
<tr>
<td><strong>EXO</strong></td>
<td>GRPO에 탐색(Entropy) 항을 추가해 다양성 확보를 노린 버전</td>
</tr>
</tbody></table>
<ul>
<li>num_generations: 프롬프트당 생성 수 (default 28)</li>
<li>num_iterations: GRPO 반복 횟수</li>
<li>temperature: 0.7</li>
</ul>
<h3 id="f-grpo-trainer-초기화">f. GRPO Trainer 초기화</h3>
<pre><code class="language-python">&quot;&quot;&quot;
grpo_train.py
1034-1043
&quot;&quot;&quot;
    # GRPO trainer 초기화
    logger.info(&quot;Initializing GRPO trainer&quot;)
    trainer = GRPOTrainer(
        model=model,
        args=grpo_config,
        processing_class=processor,
        train_dataset=train_dataset,
        eval_dataset=eval_dataset,
        reward_funcs=reward_funcs,
    )</code></pre>
<ul>
<li><code>trainer</code>에 모델, config, 데이터셋, 보상 함수 전달</li>
</ul>
<h3 id="g-학습-실행">g. 학습 실행</h3>
<pre><code class="language-python">&quot;&quot;&quot;
grpo_train.py
10451063
&quot;&quot;&quot;
    # 학습 시작
    logger.info(&quot;Starting GRPO training&quot;)
    try:
        trainer.train()

        # 최종 모델 저장
        logger.info(f&quot;Saving final model to {args.output_dir}/step-final&quot;)
        trainer.save_model()
        processor.save_pretrained(os.path.join(args.output_dir, &quot;step-final&quot;))

        logger.info(&quot;Training completed successfully!&quot;)

        if is_main_process():
            wandb.finish()

    except Exception as e:
        logger.error(f&quot;Training failed: {e}&quot;)
        raise</code></pre>
<ul>
<li>trainer.train() 실행</li>
<li>완료 후 모델 저장</li>
<li>trainer.train() 내부 파이프라인
<img alt="" src="https://velog.velcdn.com/images/starcookie/post/343635ea-3086-4ea7-b304-33e046d02ea1/image.png" /></li>
</ul>
<hr />
<h2 id="4-데이터-정제-및-처리-파이프라인">4. 데이터 정제 및 처리 파이프라인</h2>
<h3 id="a-pdf-필터링">a. PDF 필터링</h3>
<ul>
<li><p>언어 검사 (영어만): 다국어로 된 제외</p>
</li>
<li><p>폼 문서 제외: 미리 정해진 틀을 가지고 있는 문서 제외</p>
</li>
<li><p>SEO 스팸 검사(0.4% 임계값): PDF 데이터가 검색엔진 최적화 목적으로 만들어진 파일 필터링</p>
<pre><code class="language-python">&quot;&quot;&quot;
seo 키워드 12개
seo 단어 비율이 0.4% 초과 시 PDF 제외
&quot;&quot;&quot;
  def _is_download_spam(self, base_text: str) -&gt; bool:
      seo_words = {
          &quot;download&quot;,
          &quot;pdf&quot;,
          &quot;epub&quot;,
          &quot;mobi&quot;,
          &quot;free&quot;,
          &quot;ebook&quot;,
          &quot;file&quot;,
          &quot;save&quot;,
          &quot;casino&quot;,
          &quot;viagra&quot;,
          &quot;cialis&quot;,
          &quot;ciprofloxacin&quot;,
      }</code></pre>
</li>
<li><p>텍스트 품질 검사: 200자 이상, 그 중 알파벳이 50% 이상 문서만 필터링</p>
</li>
<li><p>첫 5페이지 분석: 대표 샘플로 문서 전반 품질 판단</p>
<h3 id="b-파이프라인-처리-ocr-처리">b. 파이프라인 처리 (OCR 처리)</h3>
</li>
<li><p>이미지 랜더링 파라미터:</p>
<pre><code class="language-pyrhon">  parser.add_argument(&quot;--max_page_retries&quot;, type=int, default=8, help=&quot;Max number of times we will retry rendering a page&quot;)
  parser.add_argument(&quot;--max_page_error_rate&quot;, type=float, default=0.004, help=&quot;Rate of allowable failed pages in a document, 1/250 by default&quot;)
  parser.add_argument(&quot;--workers&quot;, type=int, default=20, help=&quot;Number of workers to run at a time&quot;)
  parser.add_argument(&quot;--apply_filter&quot;, action=&quot;store_true&quot;, help=&quot;Apply basic filtering to English pdfs which are not forms, and not likely seo spam&quot;)
  parser.add_argument(&quot;--stats&quot;, action=&quot;store_true&quot;, help=&quot;Instead of running any job, reports some statistics about the current workspace&quot;)
  parser.add_argument(&quot;--markdown&quot;, action=&quot;store_true&quot;, help=&quot;Also write natural text to markdown files preserving the folder structure of the input pdfs&quot;)
  parser.add_argument(&quot;--target_longest_image_dim&quot;, type=int, help=&quot;Dimension on longest side to use for rendering the pdf pages&quot;, default=1288)</code></pre>
</li>
<li><p>문서 품질 검사: 실패 페이지 비율 0.4 초과 시 문서 제외</p>
</li>
<li><p>페이지별 처리 파라미터</p>
<pre><code class="language-python">  COMPLETION_URL = f&quot;{args.server.rstrip('/')}/chat/completions&quot;    
  MAX_RETRIES = args.max_page_retries    
  MODEL_MAX_CONTEXT = 16384    
  TEMPERATURE_BY_ATTEMPT = [0.1, 0.1, 0.2, 0.3, 0.5, 0.8, 0.9, 1.0]</code></pre>
<h3 id="c-데이터-정제-chatgpt-기반-데이터-정제">c. 데이터 정제 (ChatGPT 기반 데이터 정제)</h3>
</li>
<li><p>이미지 랜더링: ChatGPT에서는 이미지 픽셀 수를 2048픽셀수로 사용</p>
</li>
<li><p>ChatGPT 정제 파라미터: <code>temperature=0.2</code>, <code>max_tokens=16384</code>, <code>model=gpt-4o-2024-08-06(default)</code></p>
</li>
<li><p>배치 처리 파라미터</p>
<pre><code class="language-python">  parser.add_argument(&quot;--model&quot;, default=&quot;gpt-4o-2024-08-06&quot;, help=&quot;OpenAI model to use (default: gpt-4o-mini)&quot;)
  parser.add_argument(&quot;--seed&quot;, type=int, default=42, help=&quot;Random seed for shuffling documents (default: 42)&quot;)
  parser.add_argument(&quot;--batch-size&quot;, type=int, default=10, help=&quot;Number of documents to process in parallel (default: 10)&quot;)
  parser.add_argument(&quot;--max-documents&quot;, type=int, help=&quot;Maximum number of documents to process (useful for testing)&quot;)
  parser.add_argument(&quot;--skip-existing&quot;, action=&quot;store_true&quot;, help=&quot;Skip documents that already have cleaned versions in the output directory&quot;)</code></pre>
<h3 id="d-데이터셋-텍스트-필터링-최종-학습-데이터로-사용될-수-있는-수준으로-정제·검증하는-마지막-준비-단계">d. 데이터셋 텍스트 필터링 (최종 학습 데이터로 사용될 수 있는 수준으로 정제·검증하는 마지막 준비 단계)</h3>
</li>
<li><p>반복 패턴 검사: “빈 페이지로 추정되는 경우”는 다른 검사를 생략하고 빠르게 빠져나가고, 그 외엔 반복 루프등을 초기에 걸러 학습 안정성을 확보.</p>
</li>
<li><p>수학 기호 검사: 스크립트 내 리스트에 존재하는 수학 기호 52개를 제외하고, 다른 기호를 사용할 시 제외함</p>
<pre><code class="language-python"># List of mathematical symbols to check for
      math_symbols = [
          # Set theory and logic
          &quot;∈&quot;,
          &quot;∉&quot;,
          &quot;⊂&quot;,
          &quot;⊃&quot;,
          &quot;⊆&quot;,
          &quot;⊇&quot;,
          &quot;∅&quot;,
          &quot;∪&quot;,
          &quot;∩&quot;,
          &quot;∀&quot;,
          &quot;∃&quot;,
          &quot;¬&quot;,
          # Common mathematical operators
          &quot;⊕&quot;,
          &quot;⊗&quot;,
          &quot;⊙&quot;,
          # Calculus and analysis
          &quot;∂&quot;,
          &quot;∇&quot;,
          &quot;∆&quot;,
          &quot;∫&quot;,
          &quot;∬&quot;,
          &quot;∭&quot;,
          &quot;∮&quot;,
          &quot;∏&quot;,
          &quot;∑&quot;,
          &quot;√&quot;,
          &quot;∛&quot;,
          &quot;∜&quot;,
          # Arrows and relations
          &quot;⊥&quot;,
          # Other common math symbols
          &quot;∠&quot;,
          &quot;∡&quot;,
          &quot;⊤&quot;,
          &quot;⊢&quot;,
          &quot;⊣&quot;,
          &quot;∴&quot;,
          &quot;∵&quot;,
          &quot;∶&quot;,
          &quot;∷&quot;,
          &quot;∝&quot;,
          &quot;≅&quot;,
          &quot;≆&quot;,
          &quot;≇&quot;,
          &quot;≊&quot;,
          &quot;≋&quot;,
          # Matrix and vector notation
          &quot;⊕&quot;,
          &quot;⊖&quot;,
          &quot;⊗&quot;,
          &quot;⊘&quot;,
          &quot;⊙&quot;,
          &quot;⊚&quot;,
          &quot;⊛&quot;,
          &quot;⊜&quot;,
          &quot;⊝&quot;,
      ]</code></pre>
</li>
<li><p>LaTeX 명령어 유효성 검사</p>
</li>
<li><p>HTML 테이블 유효성 검사</p>
</li>
</ul>
<h3 id="e-데이터-준비">e. 데이터 준비</h3>
<ul>
<li>문서 ID 검증: 문서 ID 최소 길이가 4초과인지 확인</li>
<li>데이터를 저장할 폴더 구조 생성<h3 id="f-처리-흐름">f. 처리 흐름</h3>
```yaml</li>
</ul>
<ol>
<li><p>PDF 필터링
├─ 언어 검사 (영어만)
├─ 폼 문서 제외
├─ SEO 스팸 검사 (0.4% 임계값)
├─ 텍스트 품질 검사 (200자, 50% 알파벳)
└─ 첫 5페이지 분석</p>
</li>
<li><p>파이프라인 처리
├─ 이미지 렌더링 (1288 픽셀)
├─ OCR 처리 (최대 8회 재시도)
├─ 문서 품질 검사 (0.4% 실패율)
└─ 페이지별 처리 (20 워커)</p>
</li>
<li><p>데이터 정제
├─ 이미지 렌더링 (2048 픽셀)
├─ ChatGPT 정제 (온도 0.2)
└─ 배치 처리 (10개 동시)</p>
</li>
<li><p>텍스트 필터링
├─ 반복 패턴 검사 (30회)
├─ 수학 기호 검사 (52개)
├─ LaTeX 명령어 검사
└─ HTML 테이블 검증</p>
</li>
<li><p>데이터 준비
├─ 문서 ID 검증 (4자 이상)
└─ 폴더 구조 생성</p>
<pre><code></code></pre></li>
</ol>
<h3 id="g-파라미터-및-수치-요약-표">g. 파라미터 및 수치 요약 표</h3>
<table>
<thead>
<tr>
<th><strong>단계</strong></th>
<th><strong>파라미터</strong></th>
<th><strong>값</strong></th>
<th><strong>설명</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>PDF 필터링</strong></td>
<td><code>download_spam_threshold</code></td>
<td>0.004</td>
<td>SEO 스팸 임계값 (0.4%)</td>
</tr>
<tr>
<td></td>
<td>분석 페이지 수</td>
<td>5</td>
<td>처음 5페이지 분석</td>
</tr>
<tr>
<td></td>
<td>최소 텍스트 길이</td>
<td>200자</td>
<td>분석 최소 길이</td>
</tr>
<tr>
<td></td>
<td>알파벳 비율</td>
<td>50%</td>
<td>알파벳 비율 최소값</td>
</tr>
<tr>
<td></td>
<td>타임아웃</td>
<td>60초</td>
<td><code>pdftotext</code> 실행 제한 시간</td>
</tr>
<tr>
<td><strong>파이프라인 처리</strong></td>
<td><code>max_page_retries</code></td>
<td>8회</td>
<td>OCR 최대 재시도 횟수</td>
</tr>
<tr>
<td></td>
<td><code>max_page_error_rate</code></td>
<td>0.004</td>
<td>실패 페이지 비율 (1/250)</td>
</tr>
<tr>
<td></td>
<td><code>workers</code></td>
<td>20</td>
<td>동시 작업자 수</td>
</tr>
<tr>
<td></td>
<td><code>target_longest_image_dim</code></td>
<td>1288 픽셀</td>
<td>이미지 최대 렌더 크기</td>
</tr>
<tr>
<td></td>
<td><code>MODEL_MAX_CONTEXT</code></td>
<td>16384 토큰</td>
<td>모델 최대 컨텍스트 길이</td>
</tr>
<tr>
<td></td>
<td><code>TEMPERATURE_BY_ATTEMPT</code></td>
<td>[0.1, 0.1, 0.2, 0.3, 0.5, 0.8, 0.9, 1.0]</td>
<td>시도 횟수별 생성 온도</td>
</tr>
<tr>
<td><strong>데이터 정제</strong></td>
<td><code>target_longest_image_dim</code></td>
<td>2048 픽셀</td>
<td>정제용 고해상도 이미지 크기</td>
</tr>
<tr>
<td></td>
<td><code>temperature</code></td>
<td>0.2</td>
<td>ChatGPT 정제 온도</td>
</tr>
<tr>
<td></td>
<td><code>max_tokens</code></td>
<td>16384</td>
<td>정제 시 최대 토큰 수</td>
</tr>
<tr>
<td></td>
<td><code>batch-size</code></td>
<td>10</td>
<td>동시 처리 문서 수</td>
</tr>
<tr>
<td></td>
<td><code>seed</code></td>
<td>42</td>
<td>랜덤 시드 (재현성 확보)</td>
</tr>
<tr>
<td><strong>텍스트 필터링</strong></td>
<td><code>max_repeats</code></td>
<td>30</td>
<td>최대 반복 허용 횟수</td>
</tr>
<tr>
<td></td>
<td><code>max_ngram_size</code></td>
<td>5</td>
<td>반복 탐지 n-gram 크기</td>
</tr>
<tr>
<td></td>
<td>수학 기호 개수</td>
<td>52개</td>
<td>필터링 대상 수학 기호 개수</td>
</tr>
<tr>
<td></td>
<td>SEO 키워드 개수</td>
<td>12개</td>
<td>스팸 탐지용 키워드 수</td>
</tr>
<tr>
<td><strong>데이터 준비</strong></td>
<td>문서 ID 최소 길이</td>
<td>4자</td>
<td>문서 ID 검증 최소 길이</td>
</tr>
</tbody></table>